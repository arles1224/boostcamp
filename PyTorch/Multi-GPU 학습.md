# Multi-GPU 학습
오늘날의 딥러닝은 데이터 양이 엄청 많기 때문에 GPU를 얼마나 확보했는가가 매우 중요해졌다.

## Multi-GPU에 학습을 분산하는 방법
1. 모델을 나눈다.(Model Parallel)
	- 예전부터 사용해왔지만 병목 현상(데이터 처리 지연 현상)과 파이프라인의 어려움으로 인해 난이도가 높다.
2. 데이터를 나눈다.(Data Parallel)
	- 각각의 GPU 에 데이터를 나눠서 돌린 다음에 각각의 GPU 에서 나온 Loss 값을 미분해 그 미분값의 평균으로 전체 미분값을 구한다.
	- minibatch 를 병렬적으로 돌린다고 생각하면 된다.